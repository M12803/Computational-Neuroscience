{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee776c10-67c2-411c-b41d-75ea8bd93612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:-0.213719181821876\n",
      "Weight 1 :0.4550778724476857, Bais 1 :0.5\n",
      "Weight 2: 0.021841646967213912, Bias 2: 0.7\n",
      "Output of Weight 1: 0.40274112943524054\n",
      "Output of Weight 2: 0.6953320210805247\n",
      "Tanh activation function of neuron 1 (tanh) : 0.38229193287070207\n",
      "Tanh activation function of neuron 2 (tanh) : 0.6013964650790555\n",
      "\n",
      "Target 1: 0.5, Target 2: -0.5\n",
      "Loss: 0.6134646811779773\n",
      "Gradients:\n",
      "dL/dw1: 0.02147992584891964, dL/db1: -0.1005053718894641\n",
      "dL/dw2: -0.15025439789925196, dL/db2: 0.703045915759126\n",
      "Updated Weight 1: 0.45292987986279376, Updated Bias 1: 0.5100505371889464\n",
      "Updated Weight 2: 0.03686708675713911, Updated Bias 2: 0.6296954084240873\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import math \n",
    "# The Weight\n",
    "w1 = random.uniform(-0.5,0.5)\n",
    "w2 = random.uniform(-0.5,0.5)\n",
    "# The Bais\n",
    "b1 = 0.5\n",
    "b2 = 0.7\n",
    "# The Input\n",
    "i1 = random.uniform(-1,1)\n",
    "# Y = (weight * input) + bais\n",
    "y1 = (w1*i1) + b1 \n",
    "y2 = (w2*i1) + b2\n",
    "\n",
    "#The tanh activation function\n",
    "def tanh(x):\n",
    "    return (math.exp(x) - math.exp(-x)) / (math.exp(x) + math.exp(-x))\n",
    "\n",
    "a1 = tanh(y1)\n",
    "a2 = tanh(y2)\n",
    "\n",
    "print(f\"Input:{i1}\")\n",
    "print(f\"Weight 1 :{w1}, Bais 1 :{b1}\")\n",
    "print(f\"Weight 2: {w2}, Bias 2: {b2}\")\n",
    "print(f\"Output of Weight 1: {y1}\")\n",
    "print(f\"Output of Weight 2: {y2}\")\n",
    "print(f\"Tanh activation function of neuron 1 (tanh) : {a1}\")\n",
    "print(f\"Tanh activation function of neuron 2 (tanh) : {a2}\")\n",
    "\n",
    "# Backpropagation starts here\n",
    "# Derivative of tanh\n",
    "def tanh_derivative(x):\n",
    "    t = tanh(x)\n",
    "    return 1 - t * t\n",
    "\n",
    "# Target values (assumed, you can change these)\n",
    "t1 = 0.5  # Target for neuron 1\n",
    "t2 = -0.5  # Target for neuron 2\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Compute the loss (Mean Squared Error)\n",
    "loss = 0.5 * (t1 - a1) * (t1 - a1) + 0.5 * (t2 - a2) * (t2 - a2)\n",
    "\n",
    "# Gradients for the outputs\n",
    "dL_da1 = -(t1 - a1)\n",
    "dL_da2 = -(t2 - a2)\n",
    "\n",
    "# Gradients for the pre-activations\n",
    "dL_dy1 = dL_da1 * tanh_derivative(y1)\n",
    "dL_dy2 = dL_da2 * tanh_derivative(y2)\n",
    "\n",
    "# Gradients for the weights and biases\n",
    "dL_dw1 = dL_dy1 * i1\n",
    "dL_dw2 = dL_dy2 * i1\n",
    "dL_db1 = dL_dy1\n",
    "dL_db2 = dL_dy2\n",
    "\n",
    "# Update weights and biases\n",
    "w1 = w1 - learning_rate * dL_dw1\n",
    "w2 = w2 - learning_rate * dL_dw2\n",
    "b1 = b1 - learning_rate * dL_db1\n",
    "b2 = b2 - learning_rate * dL_db2\n",
    "\n",
    "# Print additional backpropagation results\n",
    "print(f\"\\nTarget 1: {t1}, Target 2: {t2}\")\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Gradients:\")\n",
    "print(f\"dL/dw1: {dL_dw1}, dL/db1: {dL_db1}\")\n",
    "print(f\"dL/dw2: {dL_dw2}, dL/db2: {dL_db2}\")\n",
    "print(f\"Updated Weight 1: {w1}, Updated Bias 1: {b1}\")\n",
    "print(f\"Updated Weight 2: {w2}, Updated Bias 2: {b2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbea7e2-eaec-49a4-9ae7-3734a6d8d9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
